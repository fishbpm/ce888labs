{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have made several adaptations to the mnist NN code, to improve evaluation and aid with tuning the various parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------- FIRST, I have incorporated Stratified Cross-validation -----------------\n",
    "I have found that repeated runs of any given NN config (layers, params) give quite variable results\n",
    "It is hence difficult to do any effective comparison between configurations, without doing repeated tests\n",
    "To achieve this most effectively, I have hence incorporated Stratified Cross-validation\n",
    "\n",
    "NOTE as I am using cross-validation, I have merged the mnist data into a single data-set (70,000 samples)\n",
    "7-fold cross-validation is then used to evaluate the model (10,000 test samples per fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------- SECOND, I have also parameterised the number of hidden layers -----------\n",
    "\n",
    "The model below applies 2 hidden layers, each concluding with a 0.2 dropout layer.\n",
    "Testing various configurations (1 > 4 hidden layers, single final dropout layer etc.) has shown this to be the best performing configuration\n",
    "This currently uses default hyper-parameters for the Adam optimizer (further hyper-parameter testing to follow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fish\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 64)                64        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 64)                64        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,178\n",
      "Trainable params: 55,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fish\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:55: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score - fold 1 : 0.9743102758896441 -- 10004 indices\n",
      "Score - fold 2 : 0.9799040191961608 -- 10002 indices\n",
      "Score - fold 3 : 0.9865 -- 10000 indices\n",
      "Score - fold 4 : 0.99 -- 10000 indices\n",
      "Score - fold 5 : 0.993099309930993 -- 9999 indices\n",
      "Score - fold 6 : 0.9938993899389938 -- 9999 indices\n",
      "Score - fold 7 : 0.9949979991996799 -- 9996 indices\n",
      "Average score: 0.9875301420222102\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Activation, Dropout, PReLU\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 20\n",
    "n_hidden_layers = 2\n",
    "seed = 7\n",
    "\n",
    "(X, y), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X = X.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X = np.concatenate((X, X_test), axis=0) #merge into a single sample-set for Cross-validation\n",
    "X = X.astype('float32')\n",
    "X /= 255\n",
    "\n",
    "Y = np.concatenate((y, y_test), axis=0) #merge into a single target-set for Cross-validation\n",
    "y = np_utils.to_categorical(Y, nb_classes) #convert class vectors to binary class matrices\n",
    "                                           #(for use by NN model - NOTE class vectors still needed for folding)\n",
    "inputs = Input(shape=(784,))\n",
    "x = inputs\n",
    "for layers in range(n_hidden_layers):\n",
    "    x = Dense(64)(x)\n",
    "    x = PReLU()(x) # Non-linearity\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "\n",
    "predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "    \n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer='adam',#adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "scores = []\n",
    "fold = 0\n",
    "k_fold = StratifiedKFold(n_splits=7, shuffle=True, random_state=seed)\n",
    "for train, test in k_fold.split(X, Y):\n",
    "    model.fit(X[train], y[train],\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=0, validation_data=(X[test], y[test]))\n",
    "    score = model.evaluate(X[test], y[test], verbose=0)\n",
    "    scores.append(score[1])\n",
    "    fold += 1\n",
    "    print('Score - fold', fold, \":\", score[1], \"--\", len(test), \"indices\")\n",
    "\n",
    "print('Average score:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
